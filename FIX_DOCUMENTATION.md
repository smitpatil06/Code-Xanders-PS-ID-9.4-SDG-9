# üîß AEGISFLOW - COMPLETE FIX DOCUMENTATION

## üéØ Issues Fixed

### 1. **Sensor Fusion Graph Not Working** ‚úÖ
**Problem:** Graph was trying to access `sensors.s_2` but backend was sending readable names like `LPC_Outlet_Temp`

**Solution:** 
- Updated `sensor_sim.py` to rename sensors immediately after loading
- Changed Dashboard graph to use `sensors.LPC_Outlet_Temp` and `sensors.Combustion_Pressure`
- Both graphs now work properly with live data

### 2. **Missing Failure Reasons** ‚úÖ
**Problem:** Dashboard showed status but didn't explain WHY the engine was failing

**Solution:**
- Backend now analyzes sensor thresholds and returns `failure_reasons` array
- Dashboard displays primary failure modes (e.g., "High LPC Temperature", "Excessive Vibration")
- Root cause analysis panel shows all active failure conditions

### 3. **Simulation Not Stopping on Failure** ‚úÖ
**Problem:** After engine failure, simulation kept running with cycle numbers incrementing

**Solution:**
- `sensor_sim.py` now returns `None` when engine data ends
- Backend sends `{"finished": true}` signal to frontend
- Frontend displays "ENGINE FAILURE - CLICK TO REPLAY" button
- Replay button calls `switchEngine()` to restart the same engine from cycle 1

### 4. **No Engine Selection** ‚úÖ
**Problem:** Could only view one engine (Unit 34)

**Solution:**
- Added dropdown selector with 4 demo engines
- Backend `/set_engine` API endpoint to switch units
- Each engine has different failure characteristics:
  - Unit 34: Perfect failure curve (demo default)
  - Unit 1: Healthy start
  - Unit 50: Random pattern
  - Unit 100: Critical early

### 5. **No Test File Upload Feature** ‚úÖ
**Problem:** No way to test multiple engines or upload custom test data

**Solution:**
- Created complete **UploadAnalysis** component
- Accepts NASA C-MAPSS format test files
- Backend `/upload_test` endpoint processes entire test dataset
- Returns comprehensive report with:
  - Predicted RUL for each engine
  - Estimated failure cycle
  - Status (Critical/Warning/Healthy)
  - Specific failure reasons
  - Confidence scores
- Export results to CSV
- Statistics dashboard showing total engines, critical count, etc.

### 6. **How is Backend Predicting Without Test Input?** üìä
**Clarification:**

The system works in TWO modes:

#### **Mode 1: Live Simulation (Main Dashboard)**
- Uses **training data** (`train_FD001.txt`) as a simulator
- Pretends Unit 34 (or selected engine) is running in real-time
- Each row = one operating cycle
- AI model predicts RUL based on current sensor readings
- This is like watching a recorded failure happen in slow motion

#### **Mode 2: Batch Analysis (Upload Page)**
- Uses actual **test data** (`test_FD001.txt`)
- Processes the LAST cycle of each engine
- Predicts when each engine will fail
- This is the "real" test mode for evaluating model accuracy

**Why use training data for simulation?**
- Training data includes engines that actually failed (we know their full lifecycle)
- Perfect for demonstrations since we can show a complete failure progression
- Test data only shows partial engine runs (we don't have ground truth RUL)

---

## üìÅ Files Changed

### Backend (`backend/`)
1. **main.py** - Complete rewrite
   - Added `/set_engine` endpoint
   - Added `/upload_test` endpoint  
   - WebSocket sends `failure_reasons` and handles `finished` state
   - Proper sensor threshold detection

2. **sensor_sim.py** - Enhanced
   - Loads all engines into memory once
   - `set_engine()` method to switch units dynamically
   - Returns `None` when engine data exhausted
   - Immediate sensor renaming to readable names

### Frontend (`frontend/src/`)
3. **Dashboard.tsx** - Major improvements
   - Engine selector dropdown
   - Replay button when simulation finishes
   - Root cause analysis panel with failure reasons
   - Fixed graph data keys (`sensors.LPC_Outlet_Temp` etc.)
   - Upload button to switch to batch analysis

4. **UploadAnalysis.tsx** - New component
   - File upload interface
   - Results table with sortable columns
   - Statistics summary cards
   - CSV export functionality
   - Error handling

5. **useMachineStream.ts** - Updated
   - Handles `failure_reasons` field
   - Properly manages `finished` state
   - Better error logging

---

## üöÄ How to Use

### Live Dashboard (Hackathon Demo)
1. Start backend: `python backend/main.py`
2. Start frontend: `npm run dev`
3. Select an engine from dropdown
4. Watch real-time RUL predictions
5. See failure reasons as they develop
6. When engine fails, click "REPLAY" to restart

### Batch Analysis (Test Data)
1. Click "BATCH ANALYSIS" button
2. Upload `test_FD001.txt` (or custom test file)
3. View predictions for all engines
4. Export results to CSV

---

## üé® Visual Improvements

- **Status badges** with proper colors
- **Failure reason chips** in root cause panel
- **Critical sensor highlighting** in red
- **Replay button** with pulse animation
- **Statistics dashboard** in upload mode
- **Export button** for CSV download

---

## üß™ Testing the System

### Test Case 1: Normal Operation
- Select Unit 1
- Should show "Healthy" status
- RUL slowly decreases
- No critical sensors

### Test Case 2: Failure Progression
- Select Unit 34
- Watch RUL drop below 50 (Warning)
- Watch RUL drop below 20 (Critical)
- See specific failure reasons appear
- Simulation stops at cycle 192
- Replay button appears

### Test Case 3: Batch Analysis
- Upload `test_FD001.txt`
- Should process 100 engines
- See mix of Critical/Warning/Healthy
- Export CSV for validation

---

## üìä Data Flow Explained

```
LIVE MODE:
train_FD001.txt ‚Üí sensor_sim.py ‚Üí main.py ‚Üí predict_rul() ‚Üí WebSocket ‚Üí Dashboard

BATCH MODE:
test_FD001.txt ‚Üí UploadAnalysis ‚Üí /upload_test ‚Üí predict_rul() ‚Üí Report Table
```

---

## ‚öôÔ∏è Configuration

### Sensor Thresholds (in Dashboard.tsx)
```javascript
const SAFE_LIMITS = {
  LPC_Outlet_Temp: { max: 644, label: "LPC Temp" },      
  Combustion_Pressure: { max: 554, label: "Combustion Press" }, 
  LPT_Coolant_Bleed: { max: 23.35, label: "Vibration" },    
  LPT_Outlet_Temp: { max: 1410, label: "LPT Temp" }            
};
```

### Simulation Speed (in main.py)
```python
await asyncio.sleep(0.3)  # Change to 0.1 for faster, 1.0 for slower
```

---

## üêõ Troubleshooting

### "WebSocket Error: name 'SENSOR_ORDER' is not defined"
‚Üí Use the fixed `inference.py` from previous conversation

### Graph shows no data
‚Üí Check that sensor names match between backend and frontend
‚Üí Should be `sensors.LPC_Outlet_Temp` not `sensors.s_2`

### Upload fails
‚Üí Ensure test file is in NASA C-MAPSS format (space-separated, no headers)
‚Üí Check browser console for detailed error

### Replay doesn't work
‚Üí Ensure `/set_engine` endpoint is working
‚Üí Check network tab for 200 response

---

## üéì For Hackathon Presentation

**Demo Flow:**
1. Start with Unit 34 (perfect failure curve)
2. Explain RUL prediction concept
3. Show sensor fusion graph tracking temperature/pressure
4. Point out failure reasons appearing in real-time
5. Let simulation run to completion
6. Show replay functionality
7. Switch to upload mode
8. Process test file
9. Show batch predictions and export

**Key Talking Points:**
- Real-time AI predictions using XGBoost
- Multi-sensor fusion for accurate RUL
- Explainable AI with failure root cause analysis
- Scalable batch processing for fleet monitoring
- Production-ready with WebSocket streaming

---

## üìù Notes

- Training data = 100 engines with complete lifecycles
- Test data = 100 engines with partial data (for validation)
- RUL_FD001.txt contains ground truth for test set (actual cycles remaining)
- Model uses 14 sensors + 14 rolling mean features = 28 total features
- Confidence is currently hardcoded at 94.2% (can be replaced with model uncertainty)

---

## ‚úÖ All Issues Resolved

1. ‚úÖ Sensor fusion graph working
2. ‚úÖ Temperature data displaying correctly  
3. ‚úÖ Failure reasons shown in dashboard
4. ‚úÖ Simulation stops on failure
5. ‚úÖ Replay button functional
6. ‚úÖ Engine selector added
7. ‚úÖ Batch upload page created
8. ‚úÖ Test file processing works
9. ‚úÖ CSV export available
10. ‚úÖ Complete documentation provided

**Ready for hackathon! üöÄ**
